{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eeaf7c44",
   "metadata": {},
   "source": [
    "This notebook refers to [Carlucci et al. (2019)](https://arxiv.org/pdf/1903.06864.pdf).\n",
    "We begin by explaining the methods and procedures in details before applying it to a different dataset than the one used in the article (PACS)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05aedb4",
   "metadata": {},
   "source": [
    "# Methods and procedures used for Domain Generalization by Solving Jigsaw Puzzles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e35dfe",
   "metadata": {},
   "source": [
    "## Domain Generalization\n",
    "\n",
    "Domain generalization refers to the ability of a machine learning model to generalize to unseen domains or out-of-distribution data. This is in contrast to traditional supervised learning which assumes that the training and test data come from the same domain or distribution. [Wang et al. (2022)]\n",
    "\n",
    "The models is trained on different domains, the source data (if we consider a picture style it could be drawing, painting, cartoon, ...). We want the model to be able to predict accurately the class on an unseen domain, the target data (e.g. photos).\n",
    "\n",
    "*Definition 1 (Domain).*\n",
    "Let X denote a nonempty input space and Y an output space. A domain is composed of data that are sampled from a distribution. We denote it as $\\mathcal{S} = {(x_i, y_i)}^n_{i=1}∼P_{XY}$ , where $x \\in \\mathcal{X} \\subset \\mathbb{R}^d$, $y \\in \\mathcal{Y} \\subset \\mathbb{R}$ denotes the label, and $P_{XY}$ denotes the joint distribution of the input sample and output label. X and Y denote the corresponding random variables. [Wang et al. (2022)]\n",
    "\n",
    "*Definition 2 (Domain generalization).*\n",
    "In domain generalization, we are given M training (source) domains $S_{train} = {S^i | i = 1, ..., M }$ where $S^i = {(x^i_j , y^i_j )}^{n_i}_{j=1}$ denotes the i-th domain. The joint distributions between each pair of domains are different: $P^i_{XY} \\neq P^j_{XY}$, $1 \\leq i \\neq j \\leq M$. The goal of domain generalization is to learn a robust and generalizable predictive function h : X → Y from the M training domains to achieve a minimum prediction error on an unseen test domain $S_{test}$ (i.e., $S_{test}$ cannot be accessed in training and $P^{test}_{XY} \\neq P^i_{XY}$ for i ∈ {1, ..., M}):\n",
    "$$ min_h \\mathcal{E}(x,y) \\in S_{test} [\\mathcal{l}(h(x), y)] $$\n",
    "where $\\mathcal{l}(·, ·)$ is the loss function. [Wang et al. (2022)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d08c2e2",
   "metadata": {},
   "source": [
    "## JiGENDG\n",
    "The algorithm is based on the idea of using jigsaw puzzles to train a model to be invariant to different domains. [Carlucci et al. (2019)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d617ee3b",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1928832",
   "metadata": {},
   "source": [
    "**[Carlucci et al. (2019)]** Carlucci, F. M., D'Innocente, A., Bucci, S., Caputo, B., & Tommasi, T. (2019). Domain Generalization by Solving Jigsaw Puzzles. arXiv preprint arXiv:1903.06864. [URL](https://arxiv.org/pdf/1903.06864.pdf)\n",
    "\n",
    "**[Wang et al. (2022)]** Wang, J., Lan, C., Liu, C., Ouyang, Y., Qin, T., Lu, W., Chen, Y., Zeng, W., & Yu, P. S. (2022). Generalizing to Unseen Domains: A Survey on Domain Generalization. arXiv preprint arXiv:2103.03097. [URL](https://arxiv.org/pdf/2103.03097.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5083e865",
   "metadata": {},
   "source": [
    "# Using JiGen on PACS (as in the article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16989a7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "673ae5a5",
   "metadata": {},
   "source": [
    "###  Il reste à importer les fichiers de /utils et de /optimizer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d4d8e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415285ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from IPython.core.debugger import set_trace\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from torch.autograd import Function\n",
    "from torchvision.models.resnet import BasicBlock,Bottleneck\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import join, dirname\n",
    "from collections import OrderedDict\n",
    "from itertools import chain\n",
    "from PIL import Image\n",
    "from random import sample, random\n",
    "import bisect\n",
    "import warnings\n",
    "\n",
    "\n",
    "\n",
    "# Import non utiles et même non possibles car seront définis dans le notebook\n",
    "# Ces imports sont ceux qui restent à copier coller en amont du main\n",
    "\n",
    "from optimizer.optimizer_helper import get_optim_and_scheduler\n",
    "from utils.Logger import Logger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0747db0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    source = ['photo','cartoon','sketch']\n",
    "    target = ['art_painting']\n",
    "    batch_size = 64\n",
    "    image_size = 225   # 222 si resnet18\n",
    "    \n",
    "    min_scale = 0.8               # Minimum scale percent\n",
    "    max_scale = 1.0               # Maximum scale percent\n",
    "    random_horiz_flip = 0.0       # Chance of random horizontal flip\n",
    "    jitter = 0.0                  # Color jitter amount\n",
    "    tile_random_grayscale = 0.1   # Chance of randomly greyscaling a tile\n",
    "    \n",
    "    limit_source = None     # If set, it will limit the number of training samples\n",
    "    limit_target = None     # If set, it will limit the number of testing samples\n",
    "    \n",
    "    learning_rate = 0.01\n",
    "    epochs = 30\n",
    "    n_classes = 31              # Number of classes for object prediction\n",
    "    jigsaw_n_classes = 31       # Number of permutation classes for the puzzle\n",
    "    network = \"resnet18\"        # To choose from : 'caffenet', 'alexnet', 'resnet18', 'resnet50', 'lenet'\n",
    "    jig_weight = 0.7            # Weight for the jigsaw puzzle compared to the classification\n",
    "    ooo_weight = 0              # Weight for odd one out task\n",
    "    tf_logger = True            # If True will save tensorboard compatible logs\n",
    "    val_size = 0.1              # Validation size (between 0 and 1)\n",
    "    folder_name = \"Test\"        # Used by the logger to save logs\n",
    "    bias_whole_image = 0.9      # If set, will bias the training procedure to show more often the whole image\n",
    "    TTA = False                 # Activate test time data augmentation\n",
    "    classify_only_same = False  # If true, the network will only try to classify the non scrambled images\n",
    "    train_all = True            # If true, all network weights will be trained\n",
    "    suffix = \"\"                 # Suffix for the logger\n",
    "    nesterov = False            # Use nesterov\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0128c0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b76206",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2a667a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bda70cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a1443b1",
   "metadata": {},
   "source": [
    "#### Fichiers de /model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afac8f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common to all networks definition\n",
    "class Id(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Id, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8555331c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_utils.py\n",
    "\n",
    "class GradientKillerLayer(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, **kwargs):\n",
    "        return x.view_as(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return None, None\n",
    "\n",
    "\n",
    "class ReverseLayerF(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, lambda_val):\n",
    "        ctx.lambda_val = lambda_val\n",
    "\n",
    "        return x.view_as(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        output = grad_output.neg() * ctx.lambda_val\n",
    "\n",
    "        return output, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8620984b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# caffenet\n",
    "\n",
    "\n",
    "class AlexNetCaffe(nn.Module):\n",
    "    def __init__(self, jigsaw_classes=1000, n_classes=100, domains=3, dropout=True):\n",
    "        super(AlexNetCaffe, self).__init__()\n",
    "        print(\"Using Caffe AlexNet\")\n",
    "        self.features = nn.Sequential(OrderedDict([\n",
    "            (\"conv1\", nn.Conv2d(3, 96, kernel_size=11, stride=4)),\n",
    "            (\"relu1\", nn.ReLU(inplace=True)),\n",
    "            (\"pool1\", nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True)),\n",
    "            (\"norm1\", nn.LocalResponseNorm(5, 1.e-4, 0.75)),\n",
    "            (\"conv2\", nn.Conv2d(96, 256, kernel_size=5, padding=2, groups=2)),\n",
    "            (\"relu2\", nn.ReLU(inplace=True)),\n",
    "            (\"pool2\", nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True)),\n",
    "            (\"norm2\", nn.LocalResponseNorm(5, 1.e-4, 0.75)),\n",
    "            (\"conv3\", nn.Conv2d(256, 384, kernel_size=3, padding=1)),\n",
    "            (\"relu3\", nn.ReLU(inplace=True)),\n",
    "            (\"conv4\", nn.Conv2d(384, 384, kernel_size=3, padding=1, groups=2)),\n",
    "            (\"relu4\", nn.ReLU(inplace=True)),\n",
    "            (\"conv5\", nn.Conv2d(384, 256, kernel_size=3, padding=1, groups=2)),\n",
    "            (\"relu5\", nn.ReLU(inplace=True)),\n",
    "            (\"pool5\", nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True)),\n",
    "        ]))\n",
    "        self.classifier = nn.Sequential(OrderedDict([\n",
    "            (\"fc6\", nn.Linear(256 * 6 * 6, 4096)),\n",
    "            (\"relu6\", nn.ReLU(inplace=True)),\n",
    "            (\"drop6\", nn.Dropout() if dropout else Id()),\n",
    "            (\"fc7\", nn.Linear(4096, 4096)),\n",
    "            (\"relu7\", nn.ReLU(inplace=True)),\n",
    "            (\"drop7\", nn.Dropout() if dropout else Id())]))\n",
    "\n",
    "        self.jigsaw_classifier = nn.Linear(4096, jigsaw_classes)\n",
    "        self.class_classifier = nn.Linear(4096, n_classes)\n",
    "        # self.domain_classifier = nn.Sequential(\n",
    "        #     nn.Linear(256 * 6 * 6, 1024),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Dropout(),\n",
    "        #     nn.Linear(1024, 1024),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Dropout(),\n",
    "        #     nn.Linear(1024, domains))\n",
    "\n",
    "    def get_params(self, base_lr):\n",
    "        return [{\"params\": self.features.parameters(), \"lr\": 0.},\n",
    "                {\"params\": chain(self.classifier.parameters(), self.jigsaw_classifier.parameters()\n",
    "                                 , self.class_classifier.parameters()#, self.domain_classifier.parameters()\n",
    "                                 ), \"lr\": base_lr}]\n",
    "\n",
    "    def is_patch_based(self):\n",
    "        return False\n",
    "\n",
    "    def forward(self, x, lambda_val=0):\n",
    "        x = self.features(x*57.6)  #57.6 is the magic number needed to bring torch data back to the range of caffe data, based on used std\n",
    "        x = x.view(x.size(0), -1)\n",
    "        #d = ReverseLayerF.apply(x, lambda_val)\n",
    "        x = self.classifier(x)\n",
    "        return self.jigsaw_classifier(x), self.class_classifier(x)#, self.domain_classifier(d)\n",
    "\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    " \n",
    "def caffenet(jigsaw_classes, classes):\n",
    "    model = AlexNetCaffe(jigsaw_classes, classes)\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_uniform_(m.weight, .1)\n",
    "            nn.init.constant_(m.bias, 0.)\n",
    "\n",
    "    state_dict = torch.load(os.path.join(os.path.dirname(__file__), \"pretrained/alexnet_caffe.pth.tar\"))\n",
    "    del state_dict[\"classifier.fc8.weight\"]\n",
    "    del state_dict[\"classifier.fc8.bias\"]\n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def caffenet_gap(jigsaw_classes, classes):\n",
    "    model = AlexNetCaffe(jigsaw_classes, classes)\n",
    "    state_dict = torch.load(os.path.join(os.path.dirname(__file__), \"pretrained/alexnet_caffe.pth.tar\"))\n",
    "    del state_dict[\"classifier.fc6.weight\"]\n",
    "    del state_dict[\"classifier.fc6.bias\"]\n",
    "    del state_dict[\"classifier.fc7.weight\"]\n",
    "    del state_dict[\"classifier.fc7.bias\"]\n",
    "    del state_dict[\"classifier.fc8.weight\"]\n",
    "    del state_dict[\"classifier.fc8.bias\"]\n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "    # weights are initialized in the constructor\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4750f87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alexnet.py\n",
    "\n",
    "model_urls = {\n",
    "    'alexnet': 'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth',\n",
    "}\n",
    "\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes=1000, dropout=True):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout() if dropout else Id(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout() if dropout else Id(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), 256 * 6 * 6)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def alexnet(classes, pretrained=False):\n",
    "    r\"\"\"AlexNet model architecture from the\n",
    "    `\"One weird trick...\" <https://arxiv.org/abs/1404.5997>`_ paper.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = AlexNet(classes, True)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['alexnet']))\n",
    "\n",
    "    model.classifier[-1] = nn.Linear(4096, classes)\n",
    "    nn.init.xavier_uniform_(model.classifier[-1].weight, .1)\n",
    "    nn.init.constant_(model.classifier[-1].bias, 0.)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf8cf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet.py\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, jigsaw_classes=1000, classes=100, domains=3):\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "        self.jigsaw_classifier = nn.Linear(512 * block.expansion, jigsaw_classes)\n",
    "        self.class_classifier = nn.Linear(512 * block.expansion, classes)\n",
    "        #self.domain_classifier = nn.Linear(512 * block.expansion, domains)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def is_patch_based(self):\n",
    "        return False\n",
    "\n",
    "    def forward(self, x, **kwargs):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.jigsaw_classifier(x), self.class_classifier(x)\n",
    "\n",
    "\n",
    "def resnet18(pretrained=True, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url('https://download.pytorch.org/models/resnet18-5c106cde.pth'), strict=False)\n",
    "        #model.load_state_dict(model_zoo.load_url(model_urls['resnet18']), strict=False)\n",
    "    return model\n",
    "\n",
    "def resnet50(pretrained=True, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url('https://download.pytorch.org/models/resnet50-19c8e357.pth'), strict=False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d616cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist.py\n",
    "\n",
    "# built as https://github.com/ricvolpi/generalize-unseen-domains/blob/master/model.py\n",
    "class MnistModel(nn.Module):\n",
    "    def __init__(self, jigsaw_classes=1000, n_classes=100):\n",
    "        super().__init__()\n",
    "        \n",
    "        outfeats = 1024 \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 5),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(64, 128, 5),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(128 * 4 * 4, 1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "#         outfeats = 100\n",
    "#         self.features = nn.Sequential(\n",
    "#             nn.Conv2d(3, 32, 5),\n",
    "#             nn.ReLU(True),\n",
    "#             nn.MaxPool2d(2, 2),\n",
    "#             nn.Conv2d(32, 48, 5),\n",
    "#             nn.ReLU(True),\n",
    "#             nn.MaxPool2d(2, 2)\n",
    "#         )\n",
    "#         self.classifier = nn.Sequential(\n",
    "#             nn.Linear(48 * 4 * 4, 100),\n",
    "#             nn.ReLU(True),\n",
    "#             nn.Linear(100, outfeats),\n",
    "#             nn.ReLU(True),\n",
    "#         )\n",
    "        print(\"Using LeNet (%d)\" % outfeats)\n",
    "        self.jigsaw_classifier = nn.Linear(outfeats, jigsaw_classes)\n",
    "        self.class_classifier = nn.Linear(outfeats, n_classes)\n",
    "\n",
    "    def get_params(self, base_lr):\n",
    "        raise \"No pretrained exists for LeNet - use train all\"\n",
    "\n",
    "    def is_patch_based(self):\n",
    "        return False\n",
    "\n",
    "    def forward(self, x, lambda_val=0):\n",
    "        # print(x.shape)\n",
    "        x = self.features(x)\n",
    "        # print(x.shape)\n",
    "        x = self.classifier(x.view(x.size(0), -1))\n",
    "        return self.jigsaw_classifier(x), self.class_classifier(x)\n",
    "\n",
    "\n",
    "def lenet(jigsaw_classes, classes):\n",
    "    model = MnistModel(jigsaw_classes, classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48112cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_factory.py\n",
    "\n",
    "nets_map = {\n",
    "    'caffenet': caffenet,\n",
    "    'alexnet': alexnet,\n",
    "    'resnet18': resnet18,\n",
    "    'resnet50': resnet50,\n",
    "    'lenet': lenet\n",
    "}\n",
    "\n",
    "\n",
    "def get_network(name):\n",
    "    if name not in nets_map:\n",
    "        raise ValueError('Name of network unknown %s' % name)\n",
    "\n",
    "    def get_network_fn(**kwargs):\n",
    "        return nets_map[name](**kwargs)\n",
    "\n",
    "    return get_network_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae40190",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab69e36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb555817",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ca89fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "984998b8",
   "metadata": {},
   "source": [
    "#### Fichiers de /data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2e3fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# StandardDataset.py\n",
    "\n",
    "def get_dataset(path, mode, image_size):\n",
    "    if mode == \"train\":\n",
    "        img_transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(image_size, scale=(0.7, 1.0)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[1/256., 1/256., 1/256.])  # std=[1/256., 1/256., 1/256.] #[0.229, 0.224, 0.225]\n",
    "        ])\n",
    "    else:\n",
    "        img_transform = transforms.Compose([\n",
    "            transforms.Resize(image_size),\n",
    "            # transforms.CenterCrop(image_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], std=[1/256., 1/256., 1/256.])  # std=[1/256., 1/256., 1/256.]\n",
    "        ])\n",
    "    return datasets.ImageFolder(path, transform=img_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03bdae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JigsawLoader.py\n",
    "\n",
    "\n",
    "\n",
    "def get_random_subset(names, labels, percent):\n",
    "    \"\"\"\n",
    "\n",
    "    :param names: list of names\n",
    "    :param labels:  list of labels\n",
    "    :param percent: 0 < float < 1\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    samples = len(names)\n",
    "    amount = int(samples * percent)\n",
    "    random_index = sample(range(samples), amount)\n",
    "    name_val = [names[k] for k in random_index]\n",
    "    name_train = [v for k, v in enumerate(names) if k not in random_index]\n",
    "    labels_val = [labels[k] for k in random_index]\n",
    "    labels_train = [v for k, v in enumerate(labels) if k not in random_index]\n",
    "    return name_train, name_val, labels_train, labels_val\n",
    "\n",
    "\n",
    "def _dataset_info(txt_labels):\n",
    "    with open(txt_labels, 'r') as f:\n",
    "        images_list = f.readlines()\n",
    "\n",
    "    file_names = []\n",
    "    labels = []\n",
    "    for row in images_list:\n",
    "        row = row.split(' ')\n",
    "        file_names.append(row[0])\n",
    "        labels.append(int(row[1]))\n",
    "\n",
    "    return file_names, labels\n",
    "\n",
    "\n",
    "def get_split_dataset_info(txt_list, val_percentage):\n",
    "    names, labels = _dataset_info(txt_list)\n",
    "    return get_random_subset(names, labels, val_percentage)\n",
    "\n",
    "\n",
    "class JigsawDataset(data.Dataset):\n",
    "    def __init__(self, names, labels, jig_classes=100, img_transformer=None, tile_transformer=None, patches=True, bias_whole_image=None):\n",
    "        self.data_path = \"\"\n",
    "        self.names = names\n",
    "        self.labels = labels\n",
    "\n",
    "        self.N = len(self.names)\n",
    "        self.permutations = self.__retrieve_permutations(jig_classes)\n",
    "        self.grid_size = 3\n",
    "        self.bias_whole_image = bias_whole_image\n",
    "        if patches:\n",
    "            self.patch_size = 64\n",
    "        self._image_transformer = img_transformer\n",
    "        self._augment_tile = tile_transformer\n",
    "        if patches:\n",
    "            self.returnFunc = lambda x: x\n",
    "        else:\n",
    "            def make_grid(x):\n",
    "                return torchvision.utils.make_grid(x, self.grid_size, padding=0)\n",
    "            self.returnFunc = make_grid\n",
    "\n",
    "    def get_tile(self, img, n):\n",
    "        w = float(img.size[0]) / self.grid_size\n",
    "        y = int(n / self.grid_size)\n",
    "        x = n % self.grid_size\n",
    "        tile = img.crop([x * w, y * w, (x + 1) * w, (y + 1) * w])\n",
    "        tile = self._augment_tile(tile)\n",
    "        return tile\n",
    "    \n",
    "    def get_image(self, index):\n",
    "        framename = self.data_path + '/' + self.names[index]\n",
    "        img = Image.open(framename).convert('RGB')\n",
    "        return self._image_transformer(img)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img = self.get_image(index)\n",
    "        n_grids = self.grid_size ** 2\n",
    "        tiles = [None] * n_grids\n",
    "        for n in range(n_grids):\n",
    "            tiles[n] = self.get_tile(img, n)\n",
    "\n",
    "        order = np.random.randint(len(self.permutations) + 1)  # added 1 for class 0: unsorted\n",
    "        if self.bias_whole_image:\n",
    "            if self.bias_whole_image > random():\n",
    "                order = 0\n",
    "        if order == 0:\n",
    "            data = tiles\n",
    "        else:\n",
    "            data = [tiles[self.permutations[order - 1][t]] for t in range(n_grids)]\n",
    "            \n",
    "        data = torch.stack(data, 0)\n",
    "        return self.returnFunc(data), int(order), int(self.labels[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.names)\n",
    "\n",
    "    def __retrieve_permutations(self, classes):\n",
    "        all_perm = np.load('permutations_%d.npy' % (classes))\n",
    "        # from range [1,9] to [0,8]\n",
    "        if all_perm.min() == 1:\n",
    "            all_perm = all_perm - 1\n",
    "\n",
    "        return all_perm\n",
    "\n",
    "\n",
    "class JigsawTestDataset(JigsawDataset):\n",
    "    def __init__(self, *args, **xargs):\n",
    "        super().__init__(*args, **xargs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        framename = self.data_path + '/' + self.names[index]\n",
    "        img = Image.open(framename).convert('RGB')\n",
    "        return self._image_transformer(img), 0, int(self.labels[index])\n",
    "\n",
    "\n",
    "class JigsawTestDatasetMultiple(JigsawDataset):\n",
    "    def __init__(self, *args, **xargs):\n",
    "        super().__init__(*args, **xargs)\n",
    "        self._image_transformer = transforms.Compose([\n",
    "            transforms.Resize(255, Image.BILINEAR),\n",
    "        ])\n",
    "        self._image_transformer_full = transforms.Compose([\n",
    "            transforms.Resize(225, Image.BILINEAR),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        self._augment_tile = transforms.Compose([\n",
    "            transforms.Resize((75, 75), Image.BILINEAR),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        framename = self.data_path + '/' + self.names[index]\n",
    "        _img = Image.open(framename).convert('RGB')\n",
    "        img = self._image_transformer(_img)\n",
    "\n",
    "        w = float(img.size[0]) / self.grid_size\n",
    "        n_grids = self.grid_size ** 2\n",
    "        images = []\n",
    "        jig_labels = []\n",
    "        tiles = [None] * n_grids\n",
    "        for n in range(n_grids):\n",
    "            y = int(n / self.grid_size)\n",
    "            x = n % self.grid_size\n",
    "            tile = img.crop([x * w, y * w, (x + 1) * w, (y + 1) * w])\n",
    "            tile = self._augment_tile(tile)\n",
    "            tiles[n] = tile\n",
    "        for order in range(0, len(self.permutations)+1, 3):\n",
    "            if order==0:\n",
    "                data = tiles\n",
    "            else:\n",
    "                data = [tiles[self.permutations[order-1][t]] for t in range(n_grids)]\n",
    "            data = self.returnFunc(torch.stack(data, 0))\n",
    "            images.append(data)\n",
    "            jig_labels.append(order)\n",
    "        images = torch.stack(images, 0)\n",
    "        jig_labels = torch.LongTensor(jig_labels)\n",
    "        return images, jig_labels, int(self.labels[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4877e3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat_dataset.py\n",
    "\n",
    "\n",
    "class ConcatDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset to concatenate multiple datasets.\n",
    "    Purpose: useful to assemble different existing datasets, possibly\n",
    "    large-scale datasets as the concatenation operation is done in an\n",
    "    on-the-fly manner.\n",
    "\n",
    "    Arguments:\n",
    "        datasets (sequence): List of datasets to be concatenated\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def cumsum(sequence):\n",
    "        r, s = [], 0\n",
    "        for e in sequence:\n",
    "            l = len(e)\n",
    "            r.append(l + s)\n",
    "            s += l\n",
    "        return r\n",
    "\n",
    "    def isMulti(self):\n",
    "        return isinstance(self.datasets[0], JigsawTestDatasetMultiple)\n",
    "\n",
    "    def __init__(self, datasets):\n",
    "        super(ConcatDataset, self).__init__()\n",
    "        assert len(datasets) > 0, 'datasets should not be an empty iterable'\n",
    "        self.datasets = list(datasets)\n",
    "        self.cumulative_sizes = self.cumsum(self.datasets)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.cumulative_sizes[-1]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        dataset_idx = bisect.bisect_right(self.cumulative_sizes, idx)\n",
    "        if dataset_idx == 0:\n",
    "            sample_idx = idx\n",
    "        else:\n",
    "            sample_idx = idx - self.cumulative_sizes[dataset_idx - 1]\n",
    "        return self.datasets[dataset_idx][sample_idx], dataset_idx\n",
    "\n",
    "    @property\n",
    "    def cummulative_sizes(self):\n",
    "        warnings.warn(\"cummulative_sizes attribute is renamed to \"\n",
    "                      \"cumulative_sizes\", DeprecationWarning, stacklevel=2)\n",
    "        return self.cumulative_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4ab900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_helper.py\n",
    "\n",
    "mnist = 'mnist'\n",
    "mnist_m = 'mnist_m'\n",
    "svhn = 'svhn'\n",
    "synth = 'synth'\n",
    "usps = 'usps'\n",
    "\n",
    "vlcs_datasets = [\"CALTECH\", \"LABELME\", \"PASCAL\", \"SUN\"]\n",
    "pacs_datasets = [\"art_painting\", \"cartoon\", \"photo\", \"sketch\"]\n",
    "office_datasets = [\"amazon\", \"dslr\", \"webcam\"]\n",
    "digits_datasets = [mnist, mnist, svhn, usps]\n",
    "available_datasets = office_datasets + pacs_datasets + vlcs_datasets + digits_datasets\n",
    "#office_paths = {dataset: \"/home/enoon/data/images/office/%s\" % dataset for dataset in office_datasets}\n",
    "#pacs_paths = {dataset: \"/home/enoon/data/images/PACS/kfold/%s\" % dataset for dataset in pacs_datasets}\n",
    "vlcs_paths = {dataset: \"/home/goulmdata/images/VLCS/%s/test\" % dataset for dataset in vlcs_datasets}\n",
    "#paths = {**office_paths, **pacs_paths, **vlcs_paths}\n",
    "\n",
    "dataset_std = {mnist: (0.30280363, 0.30280363, 0.30280363),\n",
    "               mnist_m: (0.2384788, 0.22375608, 0.24496263),\n",
    "               svhn: (0.1951134, 0.19804622, 0.19481073),\n",
    "               synth: (0.29410212, 0.2939651, 0.29404707),\n",
    "               usps: (0.25887518, 0.25887518, 0.25887518),\n",
    "               }\n",
    "\n",
    "dataset_mean = {mnist: (0.13909429, 0.13909429, 0.13909429),\n",
    "                mnist_m: (0.45920207, 0.46326601, 0.41085603),\n",
    "                svhn: (0.43744073, 0.4437959, 0.4733686),\n",
    "                synth: (0.46332872, 0.46316052, 0.46327512),\n",
    "                usps: (0.17025368, 0.17025368, 0.17025368),\n",
    "                }\n",
    "\n",
    "\n",
    "class Subset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, limit):\n",
    "        indices = torch.randperm(len(dataset))[:limit]\n",
    "        self.dataset = dataset\n",
    "        self.indices = indices\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[self.indices[idx]]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "\n",
    "def get_train_dataloader(args, patches):\n",
    "    dataset_list = args.source\n",
    "    assert isinstance(dataset_list, list)\n",
    "    datasets = []\n",
    "    val_datasets = []\n",
    "    img_transformer, tile_transformer = get_train_transformers(args)\n",
    "    limit = args.limit_source\n",
    "    for dname in dataset_list:\n",
    "        name_train, name_val, labels_train, labels_val = get_split_dataset_info(join(dirname(__file__), 'txt_lists', '%s_train.txt' % dname), args.val_size)\n",
    "        train_dataset = JigsawDataset(name_train, labels_train, patches=patches, img_transformer=img_transformer,\n",
    "                                      tile_transformer=tile_transformer, jig_classes=args.jigsaw_n_classes, bias_whole_image=args.bias_whole_image)\n",
    "        if limit:\n",
    "            train_dataset = Subset(train_dataset, limit)\n",
    "        datasets.append(train_dataset)\n",
    "        val_datasets.append(\n",
    "            JigsawTestDataset(name_val, labels_val, img_transformer=get_val_transformer(args),\n",
    "                              patches=patches, jig_classes=args.jigsaw_n_classes))\n",
    "    dataset = ConcatDataset(datasets)\n",
    "    val_dataset = ConcatDataset(val_datasets)\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=args.batch_size, shuffle=True, num_workers=4, pin_memory=True, drop_last=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False, num_workers=4, pin_memory=True, drop_last=False)\n",
    "    return loader, val_loader\n",
    "\n",
    "\n",
    "def get_val_dataloader(args, patches=False):\n",
    "    names, labels = _dataset_info(join(dirname(__file__), 'txt_lists', '%s_test.txt' % args.target))\n",
    "    img_tr = get_val_transformer(args)\n",
    "    val_dataset = JigsawTestDataset(names, labels, patches=patches, img_transformer=img_tr, jig_classes=args.jigsaw_n_classes)\n",
    "    if args.limit_target and len(val_dataset) > args.limit_target:\n",
    "        val_dataset = Subset(val_dataset, args.limit_target)\n",
    "        print(\"Using %d subset of val dataset\" % args.limit_target)\n",
    "    dataset = ConcatDataset([val_dataset])\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=args.batch_size, shuffle=False, num_workers=4, pin_memory=True, drop_last=False)\n",
    "    return loader\n",
    "\n",
    "\n",
    "def get_jigsaw_val_dataloader(args, patches=False):\n",
    "    names, labels = _dataset_info(join(dirname(__file__), 'txt_lists', '%s_test.txt' % args.target))\n",
    "    img_tr = [transforms.Resize((args.image_size, args.image_size))]\n",
    "    tile_tr = [transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]\n",
    "    img_transformer = transforms.Compose(img_tr)\n",
    "    tile_transformer = transforms.Compose(tile_tr)\n",
    "    val_dataset = JigsawDataset(names, labels, patches=patches, img_transformer=img_transformer,\n",
    "                                      tile_transformer=tile_transformer, jig_classes=args.jigsaw_n_classes, bias_whole_image=args.bias_whole_image)\n",
    "    if args.limit_target and len(val_dataset) > args.limit_target:\n",
    "        val_dataset = Subset(val_dataset, args.limit_target)\n",
    "        print(\"Using %d subset of val dataset\" % args.limit_target)\n",
    "    dataset = ConcatDataset([val_dataset])\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=args.batch_size, shuffle=False, num_workers=4, pin_memory=True, drop_last=False)\n",
    "    return loader\n",
    "\n",
    "\n",
    "def get_train_transformers(args):\n",
    "    img_tr = [transforms.RandomResizedCrop((int(args.image_size), int(args.image_size)), (args.min_scale, args.max_scale))]\n",
    "    if args.random_horiz_flip > 0.0:\n",
    "        img_tr.append(transforms.RandomHorizontalFlip(args.random_horiz_flip))\n",
    "    if args.jitter > 0.0:\n",
    "        img_tr.append(transforms.ColorJitter(brightness=args.jitter, contrast=args.jitter, saturation=args.jitter, hue=min(0.5, args.jitter)))\n",
    "\n",
    "    tile_tr = []\n",
    "    if args.tile_random_grayscale:\n",
    "        tile_tr.append(transforms.RandomGrayscale(args.tile_random_grayscale))\n",
    "    tile_tr = tile_tr + [transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]\n",
    "\n",
    "    return transforms.Compose(img_tr), transforms.Compose(tile_tr)\n",
    "\n",
    "\n",
    "def get_val_transformer(args):\n",
    "    img_tr = [transforms.Resize((args.image_size, args.image_size)), transforms.ToTensor(),\n",
    "              transforms.Normalize([0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]\n",
    "    return transforms.Compose(img_tr)\n",
    "\n",
    "\n",
    "def get_target_jigsaw_loader(args):\n",
    "    img_transformer, tile_transformer = get_train_transformers(args)\n",
    "    name_train, _, labels_train, _ = get_split_dataset_info(join(dirname(__file__), 'txt_lists', '%s_train.txt' % args.target), 0)\n",
    "    dataset = JigsawDataset(name_train, labels_train, patches=False, img_transformer=img_transformer,\n",
    "                            tile_transformer=tile_transformer, jig_classes=args.jigsaw_n_classes, bias_whole_image=args.bias_whole_image)\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=args.batch_size, shuffle=True, num_workers=4, pin_memory=True, drop_last=True)\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcb8427",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486de837",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665c0187",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52de49e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b803f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7049ad21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696f91e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c630175",
   "metadata": {},
   "source": [
    "#### Fichier principal train_jigsaw.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1303518e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, args, device):\n",
    "        self.args = args\n",
    "        self.device = device\n",
    "        model = get_network(args.network)(jigsaw_classes=args.jigsaw_n_classes + 1, classes=args.n_classes)\n",
    "        self.model = model.to(device)\n",
    "        # print(self.model)\n",
    "        self.source_loader, self.val_loader = get_train_dataloader(args, patches=model.is_patch_based())\n",
    "        self.target_loader = get_val_dataloader(args, patches=model.is_patch_based())\n",
    "        self.test_loaders = {\"val\": self.val_loader, \"test\": self.target_loader}\n",
    "        self.len_dataloader = len(self.source_loader)\n",
    "        print(\"Dataset size: train %d, val %d, test %d\" % (len(self.source_loader.dataset), len(self.val_loader.dataset), len(self.target_loader.dataset)))\n",
    "        self.optimizer, self.scheduler = get_optim_and_scheduler(model, args.epochs, args.learning_rate, args.train_all, nesterov=args.nesterov)\n",
    "        self.jig_weight = args.jig_weight\n",
    "        self.only_non_scrambled = args.classify_only_sane\n",
    "        self.n_classes = args.n_classes\n",
    "        if args.target in args.source:\n",
    "            self.target_id = args.source.index(args.target)\n",
    "            print(\"Target in source: %d\" % self.target_id)\n",
    "            print(args.source)\n",
    "        else:\n",
    "            self.target_id = None\n",
    "\n",
    "    def _do_epoch(self):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        self.model.train()\n",
    "        for it, ((data, jig_l, class_l), d_idx) in enumerate(self.source_loader):\n",
    "            data, jig_l, class_l, d_idx = data.to(self.device), jig_l.to(self.device), class_l.to(self.device), d_idx.to(self.device)\n",
    "            # absolute_iter_count = it + self.current_epoch * self.len_dataloader\n",
    "            # p = float(absolute_iter_count) / self.args.epochs / self.len_dataloader\n",
    "            # lambda_val = 2. / (1. + np.exp(-10 * p)) - 1\n",
    "            # if domain_error > 2.0:\n",
    "            #     lambda_val  = 0\n",
    "            # print(\"Shutting down LAMBDA to prevent implosion\")\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            jigsaw_logit, class_logit = self.model(data)  # , lambda_val=lambda_val)\n",
    "            jigsaw_loss = criterion(jigsaw_logit, jig_l)\n",
    "            # domain_loss = criterion(domain_logit, d_idx)\n",
    "            # domain_error = domain_loss.item()\n",
    "            if self.only_non_scrambled:\n",
    "                if self.target_id is not None:\n",
    "                    idx = (jig_l == 0) & (d_idx != self.target_id)\n",
    "                    class_loss = criterion(class_logit[idx], class_l[idx])\n",
    "                else:\n",
    "                    class_loss = criterion(class_logit[jig_l == 0], class_l[jig_l == 0])\n",
    "\n",
    "            elif self.target_id:\n",
    "                class_loss = criterion(class_logit[d_idx != self.target_id], class_l[d_idx != self.target_id])\n",
    "            else:\n",
    "                class_loss = criterion(class_logit, class_l)\n",
    "            _, cls_pred = class_logit.max(dim=1)\n",
    "            _, jig_pred = jigsaw_logit.max(dim=1)\n",
    "            # _, domain_pred = domain_logit.max(dim=1)\n",
    "            loss = class_loss + jigsaw_loss * self.jig_weight  # + 0.1 * domain_loss\n",
    "\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            self.logger.log(it, len(self.source_loader),\n",
    "                            {\"jigsaw\": jigsaw_loss.item(), \"class\": class_loss.item()  # , \"domain\": domain_loss.item()\n",
    "                             },\n",
    "                            # ,\"lambda\": lambda_val},\n",
    "                            {\"jigsaw\": torch.sum(jig_pred == jig_l.data).item(),\n",
    "                             \"class\": torch.sum(cls_pred == class_l.data).item(),\n",
    "                             # \"domain\": torch.sum(domain_pred == d_idx.data).item()\n",
    "                             },\n",
    "                            data.shape[0])\n",
    "            del loss, class_loss, jigsaw_loss, jigsaw_logit, class_logit\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for phase, loader in self.test_loaders.items():\n",
    "                total = len(loader.dataset)\n",
    "                if loader.dataset.isMulti():\n",
    "                    jigsaw_correct, class_correct, single_acc = self.do_test_multi(loader)\n",
    "                    print(\"Single vs multi: %g %g\" % (float(single_acc) / total, float(class_correct) / total))\n",
    "                else:\n",
    "                    jigsaw_correct, class_correct = self.do_test(loader)\n",
    "                jigsaw_acc = float(jigsaw_correct) / total\n",
    "                class_acc = float(class_correct) / total\n",
    "                self.logger.log_test(phase, {\"jigsaw\": jigsaw_acc, \"class\": class_acc})\n",
    "                self.results[phase][self.current_epoch] = class_acc\n",
    "\n",
    "    def do_test(self, loader):\n",
    "        jigsaw_correct = 0\n",
    "        class_correct = 0\n",
    "        domain_correct = 0\n",
    "        for it, ((data, jig_l, class_l), _) in enumerate(loader):\n",
    "            data, jig_l, class_l = data.to(self.device), jig_l.to(self.device), class_l.to(self.device)\n",
    "            jigsaw_logit, class_logit = self.model(data)\n",
    "            _, cls_pred = class_logit.max(dim=1)\n",
    "            _, jig_pred = jigsaw_logit.max(dim=1)\n",
    "            class_correct += torch.sum(cls_pred == class_l.data)\n",
    "            jigsaw_correct += torch.sum(jig_pred == jig_l.data)\n",
    "        return jigsaw_correct, class_correct\n",
    "\n",
    "    def do_test_multi(self, loader):\n",
    "        jigsaw_correct = 0\n",
    "        class_correct = 0\n",
    "        single_correct = 0\n",
    "        for it, ((data, jig_l, class_l), d_idx) in enumerate(loader):\n",
    "            data, jig_l, class_l = data.to(self.device), jig_l.to(self.device), class_l.to(self.device)\n",
    "            n_permutations = data.shape[1]\n",
    "            class_logits = torch.zeros(n_permutations, data.shape[0], self.n_classes).to(self.device)\n",
    "            for k in range(n_permutations):\n",
    "                class_logits[k] = F.softmax(self.model(data[:, k])[1], dim=1)\n",
    "            class_logits[0] *= 4 * n_permutations  # bias more the original image\n",
    "            class_logit = class_logits.mean(0)\n",
    "            _, cls_pred = class_logit.max(dim=1)\n",
    "            jigsaw_logit, single_logit = self.model(data[:, 0])\n",
    "            _, jig_pred = jigsaw_logit.max(dim=1)\n",
    "            _, single_logit = single_logit.max(dim=1)\n",
    "            single_correct += torch.sum(single_logit == class_l.data)\n",
    "            class_correct += torch.sum(cls_pred == class_l.data)\n",
    "            jigsaw_correct += torch.sum(jig_pred == jig_l.data[:, 0])\n",
    "        return jigsaw_correct, class_correct, single_correct\n",
    "\n",
    "    def do_training(self):\n",
    "        self.logger = Logger(self.args, update_frequency=30)  # , \"domain\", \"lambda\"\n",
    "        self.results = {\"val\": torch.zeros(self.args.epochs), \"test\": torch.zeros(self.args.epochs)}\n",
    "        for self.current_epoch in range(self.args.epochs):\n",
    "            self.scheduler.step()\n",
    "            self.logger.new_epoch(self.scheduler.get_lr())\n",
    "            self._do_epoch()\n",
    "        val_res = self.results[\"val\"]\n",
    "        test_res = self.results[\"test\"]\n",
    "        idx_best = val_res.argmax()\n",
    "        #print(\"Best val %g, corresponding test %g - best test: %g\" % (val_res.max(), test_res[idx_best], test_res.max()))\n",
    "        self.logger.save_best(test_res[idx_best], test_res.max())\n",
    "        return self.logger, self.model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e569807e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main du code python\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "args = Args()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "trainer = Trainer(args, device)\n",
    "trainer.do_training()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfe3b26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Louison Bocquet--Nouaille"
   },
   {
    "name": "Pierre-Alain Goulm"
   },
   {
    "name": "Romain Tiphaigne"
   },
   {
    "name": "Axelle Tragné"
   },
   {
    "name": "Alicia Zady"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "title": "Domain Generalization by Solving Jigsaw Puzzles",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
